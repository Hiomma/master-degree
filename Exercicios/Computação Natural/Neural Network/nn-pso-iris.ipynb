{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "# Import PySwarms\n",
    "import pyswarms as ps\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "n_inputs = 4\n",
    "n_hidden = 20\n",
    "n_classes = 3\n",
    "\n",
    "num_samples = 112"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "def logits_function(p, X):\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = p[0:80].reshape((n_inputs,n_hidden))\n",
    "    b1 = p[80:100].reshape((n_hidden,))\n",
    "    W2 = p[100:160].reshape((n_hidden,n_classes))\n",
    "    b2 = p[160:163].reshape((n_classes,))\n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
    "    logits = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    return logits          # Logits for Layer 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_prop(params, X,y):\n",
    "    logits = logits_function(params, X)\n",
    "\n",
    "    # Compute for the softmax of the logits\n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute for the negative log likelihood\n",
    "\n",
    "    corect_logprobs = -np.log(probs[range(num_samples), y])\n",
    "    loss = np.sum(corect_logprobs) / num_samples\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "def Get_PSO(f):\n",
    "    # Initialize swarm\n",
    "    options = {'c1': 2.05, 'c2': 2.05, 'w': 0.3}\n",
    "\n",
    "    # Call instance of PSO\n",
    "    dimensions = (n_inputs * n_hidden) + (n_hidden * n_classes) + n_hidden + n_classes\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=20, dimensions=dimensions, options=options)\n",
    "\n",
    "    # Perform optimization\n",
    "    cost, pos = optimizer.optimize(f, iters=1000)\n",
    "    return pos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "def predict(pos, X):\n",
    "    logits = logits_function(pos, X)\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "def Start_Iris():\n",
    "    data = pd.read_csv('databases/iris.data', names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class'])\n",
    "    target = labelencoder.fit_transform(data['class'].values)\n",
    "    data = data.drop('class', axis = 1).values\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    data = sc.fit_transform(data)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, target)\n",
    "\n",
    "    def f(x):\n",
    "        n_particles = x.shape[0]\n",
    "        j = [forward_prop(x[i], x_train, y_train) for i in range(n_particles)]\n",
    "        return np.array(j)\n",
    "\n",
    "    pos = Get_PSO(f)\n",
    "    scores = (predict(pos, x_test) == y_test)\n",
    "\n",
    "    print(\"\\n Iris \\n\")\n",
    "    print(\"Accuracy: %.2f%%\" % (100 * np.mean(scores)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 13:39:03,647 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 2.05, 'c2': 2.05, 'w': 0.3}\n",
      "pyswarms.single.global_best: 100%|██████████|1000/1000, best_cost=0.00298\n",
      "2022-03-25 13:39:06,837 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0029848305292933357, best pos: [-1.18307257e+00  8.08837216e+00  7.34947393e-01  8.54152247e-03\n",
      " -1.82157458e+00  3.87804614e+00  8.43515572e-01  2.49026358e+00\n",
      "  2.55805664e-01  1.79553664e+00 -9.17922829e+00  7.07700472e-01\n",
      "  1.99477885e+00  2.92821390e-01  1.16680272e+00 -9.35953145e-01\n",
      "  2.75307402e+00 -1.26321580e+00  8.57603312e-01  6.17356555e-01\n",
      "  2.75251983e-01  6.62744678e-02 -4.98173609e-01  3.41492146e+00\n",
      " -3.51253661e-01  1.92662285e-02 -2.30342416e-01  1.57220346e+01\n",
      "  2.34787057e+01  1.17896281e+00  2.16996255e+00 -6.69041231e-01\n",
      "  1.96616249e+00  1.07137949e+00 -2.94176776e+00  2.10688891e-01\n",
      "  9.83225678e-01 -8.04537353e-01  4.09876173e-01  1.50855695e+00\n",
      "  6.12373008e-01 -1.46258140e-01  1.43422385e+00 -2.36297753e-01\n",
      "  4.01743298e-01  2.32103728e+00 -8.78418746e-01  6.78549191e-01\n",
      "  9.11329811e-01  1.07217726e+00  1.10349324e+00  1.16979620e+00\n",
      "  7.01004760e-01  1.59591482e+00  7.08951897e+00  1.59340284e+00\n",
      "  1.11098395e+00  2.69935404e+00 -1.48039453e+00  1.10988442e+00\n",
      "  1.94914518e+00  9.11397058e-01  1.73320081e+00  5.96143657e-01\n",
      "  2.43596209e+00  9.55549852e-01 -3.02847437e-01 -4.25562226e+04\n",
      " -1.58987849e-01  2.16768991e+00 -8.12149657e-01  7.31880564e-01\n",
      "  2.06198596e+00  2.84653417e+00 -5.48716467e-01  5.35328509e-01\n",
      " -9.24852962e-01 -7.41485410e-03  1.50342878e+00  1.00125391e+00\n",
      " -1.52816968e+00  6.68933263e-02  1.18462069e+00 -2.43638731e-01\n",
      "  1.04500714e+00  1.49372536e+00  1.10374357e+01  5.42099616e-01\n",
      "  1.86214133e+00  5.38369762e-01  1.01214794e+00 -1.36631887e+00\n",
      " -4.91539634e-01 -3.46092983e+00  2.98148133e+00 -5.38995949e-01\n",
      "  4.75957806e-02  3.52867195e-01 -1.06156267e-01 -3.14343718e+00\n",
      "  1.43905026e+00 -1.16597074e+00  1.37996878e-01 -1.38581398e+00\n",
      "  1.13943276e+00  1.24358904e+00 -1.65464537e+01  7.34360235e-01\n",
      " -2.57939957e+00  4.35340290e-01  2.23574022e+00  6.77881691e-02\n",
      " -6.45648817e+00  1.97592856e+00  2.17253102e-01  9.62831028e-01\n",
      "  2.15665418e+00  8.81486416e-01  1.26021445e+00  7.89070655e-01\n",
      "  9.20849290e-01  8.50180845e-02  9.74268029e-01  2.95941480e-01\n",
      "  4.97232911e-01  2.34709578e+00  1.05937852e+00 -1.01158140e+00\n",
      "  1.68315035e+00  5.05024917e-01  2.70778042e+00  1.34545981e+00\n",
      "  6.24493764e-01  1.07476075e+00 -6.58901578e+00  3.85133810e+00\n",
      "  9.85418662e-01 -1.37141920e+00  1.41360283e+00 -1.17924930e-01\n",
      "  4.80951826e-01  6.77387912e-01  4.25218033e-01  2.15163743e+00\n",
      " -4.91569600e-02 -3.97813171e+00 -6.42529283e+00  9.40283524e+00\n",
      "  3.88484278e-01  2.72380069e+00  9.62144123e-01  4.29916604e-01\n",
      "  9.89520360e-01  2.49004892e+00 -1.19831169e+00  1.88434713e+00\n",
      "  1.64659364e+00 -5.11260963e-02 -1.37045305e+00  5.54308234e-01\n",
      " -9.14497504e-01  1.87380195e+00  9.88511479e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iris \n",
      "\n",
      "Accuracy: 97.37%\n"
     ]
    }
   ],
   "source": [
    "Start_Iris()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}