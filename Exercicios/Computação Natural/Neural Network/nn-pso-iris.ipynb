{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "# Import PySwarms\n",
    "import pyswarms as ps\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "n_inputs = 4\n",
    "n_hidden = 20\n",
    "n_classes = 3\n",
    "\n",
    "num_samples = 112"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def logits_function(p, X):\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = p[0:80].reshape((n_inputs,n_hidden))\n",
    "    b1 = p[80:100].reshape((n_hidden,))\n",
    "    W2 = p[100:160].reshape((n_hidden,n_classes))\n",
    "    b2 = p[160:163].reshape((n_classes,))\n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
    "    logits = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    return logits          # Logits for Layer 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_prop(params, X,y):\n",
    "    logits = logits_function(params, X)\n",
    "\n",
    "    # Compute for the softmax of the logits\n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute for the negative log likelihood\n",
    "\n",
    "    corect_logprobs = -np.log(probs[range(num_samples), y])\n",
    "    loss = np.sum(corect_logprobs) / num_samples\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def Get_PSO(f):\n",
    "    # Initialize swarm\n",
    "    options = {'c1': 2.05, 'c2': 2.05, 'w': 2.05 * 0.729}\n",
    "\n",
    "    # Call instance of PSO\n",
    "    dimensions = (n_inputs * n_hidden) + (n_hidden * n_classes) + n_hidden + n_classes\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=20, dimensions=dimensions, options=options)\n",
    "\n",
    "    # Perform optimization\n",
    "    cost, pos = optimizer.optimize(f, iters=1000)\n",
    "    return pos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def predict(pos, X):\n",
    "    logits = logits_function(pos, X)\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "def Start_Iris():\n",
    "    data = pd.read_csv('databases/iris.data', names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class'])\n",
    "    target = labelencoder.fit_transform(data['class'].values)\n",
    "    data = data.drop('class', axis = 1).values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, target)\n",
    "\n",
    "    def f(x):\n",
    "        n_particles = x.shape[0]\n",
    "        j = [forward_prop(x[i], x_train, y_train) for i in range(n_particles)]\n",
    "        return np.array(j)\n",
    "\n",
    "    pos = Get_PSO(f)\n",
    "    scores = (predict(pos, x_test) == y_test)\n",
    "\n",
    "    print(\"\\n Iris \\n\")\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard Deviation: \", scores.std())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 08:08:24,791 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|██████████|1000/1000, best_cost=2.11e-13\n",
      "2022-03-21 08:08:38,744 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 2.1138547261874334e-13, best pos: [ 1.15845102e+00  1.19011022e-01 -1.42770492e+00  9.67014447e-02\n",
      "  1.64960449e+00  9.76479872e-01  4.23261772e+00  8.84748721e-01\n",
      "  1.54034374e+00  4.75452477e-01 -3.17933614e+00 -7.19183701e+00\n",
      " -1.37851314e+00  1.10329063e+00 -2.64800403e+00  5.47366858e+00\n",
      " -7.22497463e+00  7.10024579e-01 -5.04866470e-01  3.65825445e+00\n",
      "  1.98005788e+00 -1.06277762e+00 -9.54339852e-01  1.27701909e+00\n",
      "  1.67922063e-01  9.09030683e-01  1.32794051e+00  1.20919244e+00\n",
      "  6.26334705e-01 -1.86844983e+00 -9.75902221e+00  5.39861844e-01\n",
      "  1.52988555e+00 -1.38178418e+00  1.55710456e-01 -1.16108476e+00\n",
      " -1.38778222e+00 -1.31308056e+00  1.58953219e+00  2.27327585e-01\n",
      "  5.86983583e-01 -8.83188859e-01  3.00115216e+00  5.24467159e-01\n",
      "  1.12610072e+00 -1.73031351e+00 -4.00248090e-01 -3.37183328e-01\n",
      " -8.66081536e-01  9.38319952e-01 -1.19883556e+00  3.79230184e-02\n",
      "  2.98767972e+00  8.28633342e-02 -2.41031349e+00 -2.46061425e-01\n",
      " -2.50722118e+00  1.91605056e+00 -7.88059191e-01  2.34181067e-01\n",
      "  1.84517789e-01 -3.75048489e+00  1.70252534e+00  4.78399787e-01\n",
      "  3.07706780e-01 -1.40405581e+00 -1.32293211e+00  9.57946125e-01\n",
      " -2.96448926e-01  2.02776988e-01 -2.06324597e+00 -1.85033430e+00\n",
      " -1.46214538e+00  1.57860649e+00  9.56508347e-01  1.11867232e+00\n",
      "  2.90403791e+00  3.99217378e-01 -3.55749304e-01  4.00458037e-01\n",
      " -3.41872756e+00  8.00207804e-01  6.31066338e-01 -2.08030224e+00\n",
      "  1.36923076e+00  2.18403566e+00 -4.07798614e+00 -1.54514474e-01\n",
      "  8.86939818e-01 -1.83663052e+00 -1.31783433e+00 -2.09698652e+00\n",
      " -3.17104785e+00  3.41228990e-01  6.70321750e-01  2.44006164e+00\n",
      " -1.91567308e+00 -4.24313838e-01  4.62561768e-02  5.90070430e-01\n",
      "  1.35013406e-01  4.08185363e-01 -4.28293183e-01 -8.67525127e-01\n",
      "  1.25757341e+00  1.71041060e+00 -2.97050649e+00 -3.93382325e-01\n",
      " -6.21264372e-01 -2.26978006e-01 -1.97909990e+00  1.00340508e+00\n",
      " -1.98935211e+00 -1.81283136e+00  2.39943642e+00 -9.99942517e-01\n",
      "  2.37828381e+00 -7.06801879e+02  6.90489362e+00  6.82982300e-02\n",
      " -1.18012771e-01 -1.72784323e-02  1.26039834e+00  2.37245895e-02\n",
      "  1.10489948e+00  2.97487077e+00  2.52193541e+00 -1.10871880e+00\n",
      "  2.42706467e-01  2.73462416e+00  4.00082218e+00 -1.12945845e+00\n",
      " -1.14615632e-01  2.31147900e-01 -3.04179730e-01 -3.49326887e-01\n",
      " -1.40023054e+00  4.26496294e+00  1.09258520e+00  2.19753537e-01\n",
      "  8.04244448e-01  5.31433829e-01 -1.07036989e+00 -1.10501627e-01\n",
      " -4.83143556e+00  1.60529860e+00 -1.09056494e+00 -9.80753766e-03\n",
      " -1.79315021e-01 -2.40643772e-01 -3.28599259e-02  1.63491054e-01\n",
      " -3.83735844e-01 -3.67461978e+00  7.49245854e+01 -1.06996580e+01\n",
      " -2.92553860e-01  1.46370370e-01 -1.35453811e-01 -1.08879425e+00\n",
      " -1.75724019e+00 -1.22517361e+00 -2.45336791e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iris \n",
      "\n",
      "Mean:  0.9736842105263158\n",
      "Standard Deviation:  0.16007269816574266\n"
     ]
    }
   ],
   "source": [
    "Start_Iris()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}