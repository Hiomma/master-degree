{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "# Import PySwarms\n",
    "import pyswarms as ps\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "n_inputs = 4\n",
    "n_hidden = 20\n",
    "n_classes = 3\n",
    "\n",
    "num_samples = 150"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "def logits_function(p, X):\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = p[0:80].reshape((n_inputs,n_hidden))\n",
    "    b1 = p[80:100].reshape((n_hidden,))\n",
    "    W2 = p[100:160].reshape((n_hidden,n_classes))\n",
    "    b2 = p[160:163].reshape((n_classes,))\n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
    "    logits = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
    "    return logits          # Logits for Layer 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_prop(params, X,y):\n",
    "    logits = logits_function(params, X)\n",
    "\n",
    "    # Compute for the softmax of the logits\n",
    "    exp_scores = np.exp(logits)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute for the negative log likelihood\n",
    "\n",
    "    corect_logprobs = -np.log(probs[range(num_samples), y])\n",
    "    loss = np.sum(corect_logprobs) / num_samples\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "def Get_PSO(f):\n",
    "    # Initialize swarm\n",
    "    options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "\n",
    "    # Call instance of PSO\n",
    "    dimensions = (n_inputs * n_hidden) + (n_hidden * n_classes) + n_hidden + n_classes\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
    "\n",
    "    # Perform optimization\n",
    "    cost, pos = optimizer.optimize(f, iters=1000)\n",
    "    return pos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "def predict(pos, X):\n",
    "    logits = logits_function(pos, X)\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    return y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "def Start_Iris(b_ES = True):\n",
    "    data = pd.read_csv('databases/iris.data', names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class'])\n",
    "    target = labelencoder.fit_transform(data['class'].values)\n",
    "    data = data.drop('class', axis = 1).values\n",
    "\n",
    "    def f(x):\n",
    "        n_particles = x.shape[0]\n",
    "        j = [forward_prop(x[i], data, target) for i in range(n_particles)]\n",
    "        return np.array(j)\n",
    "\n",
    "    pos = Get_PSO(f)\n",
    "    scores = (predict(pos, data) == target)\n",
    "\n",
    "    print(\"\\n Iris \\n\")\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard Deviation: \", scores.std())\n",
    "\n",
    "# def Start_Wine(b_ES = True):\n",
    "#     data = pd.read_csv('databases/wine.data', names = ['class', 'alcohol', 'malic acid', 'ash', 'alcalinity of ash', 'magnesium', 'total phenols', 'flavanoids', 'nonflavanoid phenols', 'proanthocyanins', 'color intensity', 'hue', 'diluted', 'proline'])\n",
    "#\n",
    "#     target = data['class'].values\n",
    "#     data_drop = data.drop('class',axis=1)\n",
    "#     data = data_drop.values\n",
    "#\n",
    "#     sc = StandardScaler()\n",
    "#     data = sc.fit_transform(data)\n",
    "#\n",
    "#     scores = []\n",
    "#     vectors = []\n",
    "#\n",
    "#     centroids  = len(set(target))\n",
    "#\n",
    "#     if(b_ES):\n",
    "#         for i in range(10):\n",
    "#             best, score = es_plus(objective, bounds, n_iter, step_size, mu, lam, centroids, data, target)\n",
    "#             scores.append(score)\n",
    "#             vectors.append(best)\n",
    "#     else:\n",
    "#         for i in range(10):\n",
    "#             solution = differential_evolution(pop_size, iter, F, cr, data, target, centroids)\n",
    "#             scores.append(solution[1])\n",
    "#             vectors.append(solution[0])\n",
    "#\n",
    "#     scores = np.array(scores)\n",
    "#\n",
    "#     print(\"\\n Wine \\n\")\n",
    "#     print(\"Mean: \", scores.mean())\n",
    "#     print(\"Standard Deviation: \", scores.std())\n",
    "#     print(\"Min: \", scores.min())\n",
    "#     print(\"Max: \", scores.max())\n",
    "#     print(\"Best vector\", vectors[scores.argmax()])\n",
    "#\n",
    "# def Start_Breast_Cancer(b_ES = True):\n",
    "#     data = pd.read_csv('databases/breast-cancer.data', names = ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "#                                                                 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "#                                                                 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "#                                                                 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "#                                                                 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "#                                                                 'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "#                                                                 'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "#                                                                 'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "#                                                                 'symmetry_worst', 'fractal_dimension_worst'])\n",
    "#\n",
    "#     data = data.drop('id',axis=1)\n",
    "#\n",
    "#     data['diagnosis'] = data['diagnosis'].map({'M':1,'B':0})\n",
    "#\n",
    "#     datas = pd.DataFrame(preprocessing.scale(data.iloc[:,1:31]))\n",
    "#     datas.columns = list(data.iloc[:,1:31].columns)\n",
    "#     target = data['diagnosis']\n",
    "#     data = datas.values\n",
    "#\n",
    "#     scores = []\n",
    "#     vectors = []\n",
    "#\n",
    "#     centroids = len(set(target))\n",
    "#\n",
    "#     if(b_ES):\n",
    "#         for i in range(10):\n",
    "#             best, score = es_plus(objective, bounds, n_iter, step_size, mu, lam, centroids, data, target)\n",
    "#             scores.append(score)\n",
    "#             vectors.append(best)\n",
    "#     else:\n",
    "#         for i in range(10):\n",
    "#             solution = differential_evolution(pop_size, iter, F, cr, data, target, centroids)\n",
    "#             scores.append(solution[1])\n",
    "#             vectors.append(solution[0])\n",
    "#\n",
    "#     scores = np.array(scores)\n",
    "#\n",
    "#     print(\"\\n Breast Cancer \\n\")\n",
    "#     print(\"Mean: \", scores.mean())\n",
    "#     print(\"Standard Deviation: \", scores.std())\n",
    "#     print(\"Min: \", scores.min())\n",
    "#     print(\"Max: \", scores.max())\n",
    "#     print(\"Best vector\", vectors[scores.argmax()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 15:08:37,111 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|██████████|1000/1000, best_cost=0.0182\n",
      "2022-03-06 15:09:07,531 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.018221833148987576, best pos: [ 5.64704657e-01  1.77363594e-01 -1.62001346e+00  9.64797210e-01\n",
      "  2.88935153e-01  5.20451980e-01  5.94741293e-01 -3.35928187e-01\n",
      " -1.01324648e+00 -1.87210349e+00 -1.82650788e+00  1.54800755e+00\n",
      " -3.44260446e-01  1.59102564e+00  1.00601672e+00 -9.62158742e-01\n",
      "  7.21091214e-01  5.19251159e-01  2.56329257e+00  4.17093168e-01\n",
      " -9.85735097e-01 -2.58215376e+00 -1.07653877e+00  8.36166083e-01\n",
      " -1.70580313e+00  3.86526885e-01 -8.07632344e-01  4.17660690e+00\n",
      " -8.21354256e-01 -3.16169759e-01 -2.24849623e+00 -3.01756903e-01\n",
      "  1.66037796e+00  2.46396550e+00 -7.88877444e-01 -9.68119439e-01\n",
      " -3.74135011e-01  5.33961618e-01 -5.55836088e-01  6.37544254e+00\n",
      "  9.68201134e-01  7.61029369e-01  2.11433834e-02 -5.00461646e-01\n",
      " -1.98251161e+00 -3.04729027e+00  8.94615885e-01 -3.17570036e+00\n",
      "  1.47951034e-01  2.49034920e+00 -3.35406802e-01  1.08897728e+00\n",
      " -1.36295803e+00  1.65615448e+00 -1.25691498e-01 -5.73643368e-01\n",
      " -1.96931104e+00 -2.35894503e+00 -1.32701437e-01  4.19617592e+00\n",
      "  4.61686293e+00  1.09863485e+00 -3.46299427e-01 -1.80519640e+00\n",
      "  4.16007781e-01  5.37130489e+00  2.55985499e-01  1.75631266e-01\n",
      " -1.43151895e-01  2.87745652e+00 -2.38165270e-02  2.59282337e+00\n",
      " -8.77001004e-01  8.94896432e-01  1.43301695e+00  1.02547256e+00\n",
      "  2.14585185e+00 -1.91644034e+00 -6.83046868e+00 -4.41868291e+00\n",
      "  6.91278809e+00  5.74998539e-01 -3.02707285e+00  1.11527400e+00\n",
      "  6.52437600e-01  9.39041501e-01  5.12107315e-01  2.22747520e+00\n",
      "  1.68158491e+00  1.97739444e-01  1.22119631e+00 -1.01394818e+00\n",
      "  4.53548774e+00 -1.80518802e-01  1.79409682e+00  4.03092213e-01\n",
      "  2.15077277e+00  7.09074346e+00  6.95966189e-01  1.15630993e+00\n",
      "  9.57554526e-01 -8.21961963e-01 -4.22088437e-01 -1.92476503e-01\n",
      "  5.03645506e-01 -1.15835284e-01  1.90146650e+00  1.10344916e+00\n",
      " -1.09011065e+00  2.36493579e+00 -5.92764279e-01  1.14826628e+00\n",
      " -9.92168830e-01  9.14574839e-01  9.80428512e-01  7.23252879e-01\n",
      " -1.21622834e+00  2.14361867e+01  9.83850374e-01  4.25280552e+00\n",
      "  3.57155713e-01  1.62672452e+00 -1.71661492e+00 -1.18129219e+00\n",
      " -1.59166756e+00  2.55657591e-01 -4.17403360e-01 -1.83956397e+01\n",
      "  1.28714033e-01 -1.80122665e-01 -3.76226182e-01  7.16532211e-01\n",
      "  7.33714188e-01  9.24397847e-01  2.09438559e+00  1.45148051e+00\n",
      "  2.52645487e+00  9.26783918e-02 -3.95803765e+01 -1.90099590e-01\n",
      "  7.09652954e-01 -4.79652085e-01 -1.36988478e-01 -2.27191343e-01\n",
      "  1.53292424e+00  5.32862746e-01 -1.19529777e+00  1.16847088e+00\n",
      " -2.39110792e-01  2.06709573e-01 -2.48162635e+01 -4.84514516e+00\n",
      "  2.31598142e+00 -1.25375423e+00  5.80489636e-01  6.04918819e+00\n",
      " -8.14766079e-01  9.99866884e-02  2.38958695e+00  2.84894203e-01\n",
      "  2.97761369e+00 -1.30362827e+00 -2.62665765e+01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iris \n",
      "\n",
      "Mean:  0.9866666666666667\n",
      "Standard Deviation:  0.11469767022723505\n",
      "Min:  False\n",
      "Max:  True\n"
     ]
    }
   ],
   "source": [
    "Start_Iris()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}