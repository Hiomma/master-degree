{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# differential evolution search of the two-dimensional sphere objective function\n",
    "from numpy.random import rand\n",
    "from numpy.random import choice\n",
    "from numpy import asarray\n",
    "from numpy import clip\n",
    "from numpy import argmax\n",
    "from numpy import max\n",
    "from numpy import around\n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def Evaluate_State(state, data, target):\n",
    "    #finding the distance between centroids and all the data points\n",
    "    distances = cdist(data, state,'euclidean') #Step 2\n",
    "\n",
    "    k = len(state)\n",
    "\n",
    "    #Centroid with the minimum Distance\n",
    "    points = np.array([np.argmin(i) for i in distances]) #Step 3\n",
    "\n",
    "    #Repeating the above steps for a defined number of iterations\n",
    "    #Step 4\n",
    "    for _ in range(10):\n",
    "        _state = state\n",
    "        state = []\n",
    "        for idx in range(k):\n",
    "            #Updating Centroids by taking mean of Cluster it belongs to\n",
    "            if(len(data[points == idx]) == 0):\n",
    "                state.append(_state[idx])\n",
    "            else:\n",
    "                state.append(data[points == idx].mean(axis=0))\n",
    "\n",
    "        state = np.vstack(state) #Updated Centroids\n",
    "\n",
    "        distances = cdist(data, state,'euclidean')\n",
    "        points = np.array([np.argmin(i) for i in distances])\n",
    "\n",
    "    return accuracy_score(target, points), state\n",
    "\n",
    "# define mutation operation\n",
    "def mutation(x, F):\n",
    "    return x[0] + F * (x[1] - x[2])\n",
    "\n",
    "\n",
    "# define boundary check operation\n",
    "def check_bounds(mutated, bounds):\n",
    "    array = []\n",
    "    for i in range(len(mutated)):\n",
    "        auxiliar = []\n",
    "        for g in range(len(bounds)):\n",
    "            auxiliar.append(clip(mutated[i][g],bounds[g][0],bounds[g][1]))\n",
    "        if not np.array_equal(array, []):\n",
    "            array = np.vstack([array, auxiliar])\n",
    "        else:\n",
    "            array.append(auxiliar)\n",
    "    mutated_bound = array\n",
    "    return mutated_bound\n",
    "\n",
    "\n",
    "# define crossover operation\n",
    "def crossover(mutated, target, dims, cr):\n",
    "    # generate a uniform random value for every dimension\n",
    "    p = rand(len(mutated))\n",
    "    # generate trial vector by binomial crossover\n",
    "    trial = np.array([mutated[i] if p[i] < cr else target[i] for i in range(len(mutated))])\n",
    "    return trial\n",
    "\n",
    "def differential_evolution(pop_size, iter, F, cr, data, target, centroids):\n",
    "    # initialise population of candidate solutions randomly within the specified bounds\n",
    "    bounds = np.array([[min(data[:,i]),max(data[:,i])] for i in range(data.shape[1])])\n",
    "\n",
    "    pop = np.array([[[random.uniform(bounds[i][0], bounds[i][1]) for i in range(data.shape[1])] for _ in range(centroids)] for _ in range(pop_size)])\n",
    "    pop = np.squeeze(pop)\n",
    "    # evaluate initial population of candidate solutions\n",
    "    obj_all = np.array([Evaluate_State(ind, data, target) for ind in pop])\n",
    "    # find the best performing vector of initial population\n",
    "    best_vector = obj_all[argmax(obj_all[:,0]),1]\n",
    "    best_obj = max(obj_all[:,0])\n",
    "    prev_obj = best_obj\n",
    "    # initialise list to store the objective function value at each iteration\n",
    "    obj_iter = list()\n",
    "    # run iterations of the algorithm\n",
    "    for i in range(iter):\n",
    "        # iterate over all candidate solutions\n",
    "        for j in range(pop_size):\n",
    "            # choose three candidates, a, b and c, that are not the current one\n",
    "            candidates = [candidate for candidate in range(pop_size) if candidate != j]\n",
    "            a, b, c = pop[choice(candidates, 3, replace=False)]\n",
    "            # perform mutation\n",
    "            mutated = mutation([a, b, c], F)\n",
    "            # check that lower and upper bounds are retained after mutation\n",
    "            mutated = check_bounds(mutated, bounds)\n",
    "            # perform crossover\n",
    "            trial = crossover(mutated, pop[j], len(bounds), cr)\n",
    "            # compute objective function value for target vector\n",
    "            obj_target = Evaluate_State(pop[j], data, target)\n",
    "            # compute objective function value for trial vector\n",
    "            obj_trial = Evaluate_State(trial, data, target)\n",
    "            # perform selection\n",
    "            if obj_trial[0] > obj_target[0]:\n",
    "                # replace the target vector with the trial vector\n",
    "                pop[j] = trial[1]\n",
    "                # store the new objective function value\n",
    "                obj_all[j, 0] = obj_trial[0]\n",
    "        # find the best performing vector at each iteration\n",
    "        best_obj = max(obj_all[:,0])\n",
    "\n",
    "        if best_obj > prev_obj:\n",
    "            best_vector = obj_all[argmax(obj_all[:,0]),1]\n",
    "            prev_obj = best_obj\n",
    "            obj_iter.append(best_obj)\n",
    "            # report progress at each iteration\n",
    "         #   print('Iteration: %d f([%s]) = %.5f' % (i, around(best_vector, decimals=5), best_obj))\n",
    "    return [best_vector, prev_obj, obj_iter]\n",
    "\n",
    "\n",
    "# define population size\n",
    "pop_size = 10\n",
    "\n",
    "# define number of iterations\n",
    "iter = 100\n",
    "# define scale factor for mutation\n",
    "F = 0.5\n",
    "# define crossover rate for recombination\n",
    "cr = 0.7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "\n",
    "# evolution strategy (mu + lambda) of the ackley objective function\n",
    "from numpy import asarray\n",
    "from numpy import argsort\n",
    "from numpy.random import randn\n",
    "from numpy.random import rand\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy.random import seed\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# objective function\n",
    "def objective(state, data, target):\n",
    "    #finding the distance between centroids and all the data points\n",
    "    distances = cdist(data, state,'euclidean') #Step 2\n",
    "\n",
    "    k = len(state)\n",
    "\n",
    "    #Centroid with the minimum Distance\n",
    "    points = np.array([np.argmin(i) for i in distances]) #Step 3\n",
    "\n",
    "    #Repeating the above steps for a defined number of iterations\n",
    "    #Step 4\n",
    "    for _ in range(10):\n",
    "        _state = state\n",
    "        state = []\n",
    "        for idx in range(k):\n",
    "            #Updating Centroids by taking mean of Cluster it belongs to\n",
    "            if(len(data[points == idx]) == 0):\n",
    "                state.append(_state[idx])\n",
    "            else:\n",
    "                state.append(data[points == idx].mean(axis=0))\n",
    "\n",
    "        state = np.vstack(state) #Updated Centroids\n",
    "\n",
    "        distances = cdist(data, state,'euclidean')\n",
    "        points = np.array([np.argmin(i) for i in distances])\n",
    "\n",
    "    return accuracy_score(target, points), state\n",
    "\n",
    "# check if a point is within the bounds of the search\n",
    "def in_bounds(point, bounds):\n",
    "    #print(\"Point:\", point)\n",
    "    #print(\"Bounds:\", bounds)\n",
    "\n",
    "    # enumerate all dimensions of the point\n",
    "    for d in range(len(point)):\n",
    "        # check if out of bounds for this dimension\n",
    "        for j in range(len(point[d])):\n",
    "            if point[d][j] < bounds[j][0] or point[d][j] > bounds[j][1]:\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# evolution strategy (mu + lambda) algorithm\n",
    "def es_plus(objective, bounds, n_iter, step_size, mu, lam, centroids, data, target):\n",
    "    bounds = np.array([[min(data[:,i]),max(data[:,i])] for i in range(data.shape[1])])\n",
    "\n",
    "    best, best_eval = 0, 0\n",
    "    # calculate the number of children per parent\n",
    "    n_children = int(lam / mu)\n",
    "    # initial population\n",
    "    population = [[[random.uniform(bounds[i][0], bounds[i][1]) for i in range(data.shape[1])] for _ in range(centroids)] for _ in range(lam)]\n",
    "    # perform the search\n",
    "\n",
    "    population = np.array(population)\n",
    "\n",
    "    for epoch in range(n_iter):\n",
    "        # evaluate fitness for the population\n",
    "        scores = np.array([objective(c, data, target) for c in population])\n",
    "        # rank scores in ascending order\n",
    "        ranks = argsort(argsort(scores[:, 0]))[::-1]\n",
    "        # select the indexes for the top mu ranked solutions\n",
    "        selected = [i for i,_ in enumerate(ranks) if ranks[i] < mu]\n",
    "\n",
    "        # create children from parents\n",
    "        children = list()\n",
    "\n",
    "        for i in selected:\n",
    "            # check if this parent is the best solution ever seen\n",
    "            if scores[i][0] > best_eval:\n",
    "                best, best_eval = scores[i][1], scores[i][0]\n",
    "            #  print('%d, Best: f(%s) = %.5f' % (epoch, best, best_eval))\n",
    "            # keep the parent\n",
    "            children.append(scores[i][1])\n",
    "            # create children for parent\n",
    "            for _ in range(n_children):\n",
    "                child = None\n",
    "                while child is None or not in_bounds(child, bounds):\n",
    "                    child = scores[i][1] + randn(np.array(scores[i][1]).shape[0], np.array(scores[i][1]).shape[1]) * step_size\n",
    "                children.append(child)\n",
    "        # replace population with children\n",
    "        population = np.array(children)\n",
    "\n",
    "    return [best, best_eval]\n",
    "\n",
    "# seed the pseudorandom number generator\n",
    "seed(1)\n",
    "# define range for input\n",
    "bounds = asarray([0, 8.0])\n",
    "# define the total iterations\n",
    "n_iter = 100\n",
    "# define the maximum step size\n",
    "step_size = 0.15\n",
    "# number of parents selected\n",
    "mu = 4\n",
    "# the number of children generated by parents\n",
    "lam = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "def Start_Iris(b_ES = True):\n",
    "    data = pd.read_csv('databases/iris.data', names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class'])\n",
    "    target = labelencoder.fit_transform(data['class'].values)\n",
    "    data = data.drop('class', axis = 1).values\n",
    "\n",
    "    scores = []\n",
    "    vectors = []\n",
    "\n",
    "    centroids = len(set(target))\n",
    "\n",
    "    if(b_ES):\n",
    "        for i in range(10):\n",
    "            best, score = es_plus(objective, bounds, n_iter, step_size, mu, lam, centroids, data, target)\n",
    "            scores.append(score)\n",
    "            vectors.append(best)\n",
    "    else:\n",
    "        for i in range(10):\n",
    "            solution = differential_evolution(pop_size, iter, F, cr, data, target, centroids)\n",
    "            scores.append(solution[1])\n",
    "            vectors.append(solution[0])\n",
    "\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    print(\"\\n Iris \\n\")\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard Deviation: \", scores.std())\n",
    "    print(\"Min: \", scores.min())\n",
    "    print(\"Max: \", scores.max())\n",
    "    print(\"Best vector\", vectors[scores.argmax()])\n",
    "\n",
    "def Start_Wine(b_ES = True):\n",
    "    data = pd.read_csv('databases/wine.data', names = ['class', 'alcohol', 'malic acid', 'ash', 'alcalinity of ash', 'magnesium', 'total phenols', 'flavanoids', 'nonflavanoid phenols', 'proanthocyanins', 'color intensity', 'hue', 'diluted', 'proline'])\n",
    "\n",
    "    target = data['class'].values\n",
    "    data_drop = data.drop('class',axis=1)\n",
    "    data = data_drop.values\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    data = sc.fit_transform(data)\n",
    "\n",
    "    scores = []\n",
    "    vectors = []\n",
    "\n",
    "    centroids  = len(set(target))\n",
    "\n",
    "    if(b_ES):\n",
    "        for i in range(10):\n",
    "            best, score = es_plus(objective, bounds, n_iter, step_size, mu, lam, centroids, data, target)\n",
    "            scores.append(score)\n",
    "            vectors.append(best)\n",
    "    else:\n",
    "        for i in range(10):\n",
    "            solution = differential_evolution(pop_size, iter, F, cr, data, target, centroids)\n",
    "            scores.append(solution[1])\n",
    "            vectors.append(solution[0])\n",
    "\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    print(\"\\n Wine \\n\")\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard Deviation: \", scores.std())\n",
    "    print(\"Min: \", scores.min())\n",
    "    print(\"Max: \", scores.max())\n",
    "    print(\"Best vector\", vectors[scores.argmax()])\n",
    "\n",
    "def Start_Breast_Cancer(b_ES = True):\n",
    "    data = pd.read_csv('databases/breast-cancer.data', names = ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "                                                                'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "                                                                'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "                                                                'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "                                                                'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "                                                                'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "                                                                'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "                                                                'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "                                                                'symmetry_worst', 'fractal_dimension_worst'])\n",
    "\n",
    "    data = data.drop('id',axis=1)\n",
    "\n",
    "    data['diagnosis'] = data['diagnosis'].map({'M':1,'B':0})\n",
    "\n",
    "    datas = pd.DataFrame(preprocessing.scale(data.iloc[:,1:31]))\n",
    "    datas.columns = list(data.iloc[:,1:31].columns)\n",
    "    target = data['diagnosis']\n",
    "    data = datas.values\n",
    "\n",
    "    scores = []\n",
    "    vectors = []\n",
    "\n",
    "    centroids = len(set(target))\n",
    "\n",
    "    if(b_ES):\n",
    "        for i in range(10):\n",
    "            best, score = es_plus(objective, bounds, n_iter, step_size, mu, lam, centroids, data, target)\n",
    "            scores.append(score)\n",
    "            vectors.append(best)\n",
    "    else:\n",
    "        for i in range(10):\n",
    "            solution = differential_evolution(pop_size, iter, F, cr, data, target, centroids)\n",
    "            scores.append(solution[1])\n",
    "            vectors.append(solution[0])\n",
    "\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    print(\"\\n Breast Cancer \\n\")\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard Deviation: \", scores.std())\n",
    "    print(\"Min: \", scores.min())\n",
    "    print(\"Max: \", scores.max())\n",
    "    print(\"Best vector\", vectors[scores.argmax()])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iris \n",
      "\n",
      "Mean:  0.6673333333333333\n",
      "Standard Deviation:  0.2847915416971196\n",
      "Min:  0.24\n",
      "Max:  0.8933333333333333\n",
      "Best vector [[5.006      3.418      1.464      0.244     ]\n",
      " [5.9016129  2.7483871  4.39354839 1.43387097]\n",
      " [6.85       3.07368421 5.74210526 2.07105263]]\n",
      "\n",
      " Wine \n",
      "\n",
      "Mean:  0.5089887640449438\n",
      "Standard Deviation:  0.21472436331959321\n",
      "Min:  0.028089887640449437\n",
      "Max:  0.702247191011236\n",
      "Best vector [[ 0.16490746  0.87154706  0.18689833  0.52436746 -0.07547277 -0.97933029\n",
      "  -1.21524764  0.72606354 -0.77970639  0.94153874 -1.16478865 -1.29241163\n",
      "  -0.40708796]\n",
      " [ 0.87809728 -0.30457633  0.31894179 -0.66452366  0.56488825  0.87650546\n",
      "   0.94363903 -0.58558981  0.58178294  0.16718842  0.48372814  0.76705349\n",
      "   1.15834713]\n",
      " [-0.93900326 -0.39196582 -0.43920097  0.20898793 -0.46377382 -0.05334831\n",
      "   0.06690377 -0.01982215  0.06479192 -0.88207529  0.45298189  0.28973833\n",
      "  -0.75602559]]\n",
      "\n",
      " Breast Cancer \n",
      "\n",
      "Mean:  0.9123022847100175\n",
      "Standard Deviation:  0.0012302284710017787\n",
      "Min:  0.9103690685413005\n",
      "Max:  0.9156414762741653\n",
      "Best vector [[-0.46987847 -0.23616585 -0.48480972 -0.46662039 -0.28030501 -0.46949164\n",
      "  -0.53714065 -0.55374169 -0.27554981 -0.09881049 -0.41018826 -0.02158144\n",
      "  -0.40818432 -0.38985586 -0.01061427 -0.30209044 -0.28458394 -0.34980365\n",
      "  -0.06395669 -0.17585504 -0.50272714 -0.24893086 -0.51313546 -0.48721052\n",
      "  -0.29174263 -0.43556393 -0.48315489 -0.54154012 -0.28197955 -0.27636223]\n",
      " [ 1.04921727  0.52734761  1.08255806  1.04194213  0.62590836  1.0483535\n",
      "   1.19941066  1.23648002  0.6152902   0.22063933  0.91593175  0.04819038\n",
      "   0.91145704  0.8705304   0.02370117  0.67455421  0.635463    0.78109564\n",
      "   0.14281238  0.3926763   1.12256686  0.55585129  1.14580816  1.08791893\n",
      "   0.65144803  0.97259446  1.07886292  1.20923448  0.62964752  0.6171043 ]]\n"
     ]
    }
   ],
   "source": [
    "Start_Iris(False)\n",
    "Start_Wine(False)\n",
    "Start_Breast_Cancer(False)\n",
    "\n",
    "Start_Iris()\n",
    "Start_Wine()\n",
    "Start_Breast_Cancer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}